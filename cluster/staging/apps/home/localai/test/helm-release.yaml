apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: &appname localai
  namespace: home
spec:
  interval: 5m
  chart:
    spec:
      chart: app-template
      version: 2.2.0
      interval: 5m
      sourceRef:
        kind: HelmRepository
        name: bjw-s-charts
        namespace: flux-system
  # See https://github.com/bjw-s/helm-charts/blob/main/charts/library/common/values.yaml
  values:

    defaultPodOptions:
      nodeSelector:
        node-role.kubernetes.io/worker: 'true'

    controllers:
      main:
        initContainers:
          download-model:
            command: [/bin/sh, -c]
            args:
              - |
                ## A simpler and more secure way if you have a way of staging an archive with the files you need
                #wget "https://s3.${SECRET_DEV_DOMAIN}/public/stablediffusion.tar" -P /tmp
                #tar -xzvf /tmp/stablediffusion.tar -C $MODELS_PATH
                #rm -rf /tmp/stablediffusion.tar

                ## A more general and less secure way that grab all the files from github
                ## Details here: https://github.com/go-skynet/LocalAI
                ## And here: https://github.com/lenaxia/stablediffusion-bins/releases/tag/2023.05.24
                mkdir $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/AutoencoderKL-256-256-fp16-opt.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/AutoencoderKL-512-512-fp16-opt.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/AutoencoderKL-base-fp16.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/FrozenCLIPEmbedder-fp16.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/UNetModel-256-256-MHA-fp16-opt.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/UNetModel-512-512-MHA-fp16-opt.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/UNetModel-base-MHA-fp16.param" -P $MODELS_PATH/stablediffusion_assets
                wget "https://github.com/EdVince/Stable-Diffusion-NCNN/raw/main/x86/linux/assets/log_sigmas.bin" -P $MODELS_PATH/stablediffusion_assets
                wget "https://raw.githubusercontent.com/EdVince/Stable-Diffusion-NCNN/main/x86/linux/assets/vocab.txt" -P $MODELS_PATH/stablediffusion_assets
                wget "https://github.com/lenaxia/stablediffusion-bins/releases/download/2023.05.24/UNetModel-MHA-fp16.bin" -P $MODELS_PATH/stablediffusion_assets
                wget "https://github.com/lenaxia/stablediffusion-bins/releases/download/2023.05.24/FrozenCLIPEmbedder-fp16.bin" -P $MODELS_PATH/stablediffusion_assets
                wget "https://github.com/lenaxia/stablediffusion-bins/releases/download/2023.05.24/AutoencoderKL-fp16.bin" -P $MODELS_PATH/stablediffusion_assets
                wget "https://github.com/lenaxia/stablediffusion-bins/releases/download/2023.05.24/AutoencoderKL-encoder-512-512-fp16.bin" -P $MODELS_PATH/stablediffusion_assets

                cat << "EOF" >> $MODELS_PATH/stablediffusion.yaml
                name: stablediffusion
                backend: stablediffusion
                asset_dir: stablediffusion_assets
                EOF

            env:
              - name: URL
                value: https://gpt4all.io/models/ggml-gpt4all-j.bin
              - name: MODELS_PATH
                value: /models
            volumeMounts:
              - name: models
                mountPath: /models
            securityContext:
              runAsUser: 0

            image:
              repository: busybox@sha256
              tag: 3fbc632167424a6d997e74f52b878d7cc478225cffac6bc977eedfe51c7f4e79
        containers:
          main:
            image:
              repository: quay.io/go-skynet/local-ai
              tag: v1.40.0

            env:
              - name: THREADS
                value: 4
              - name: CONTEXT_SIZE
                value: 512
              - name: MODELS_PATH
                value: /models
              - name: IMAGE_PATH
                value: /tmp
              - name: BUILD_TYPE
                value: openblas
#      value: clblas
#    - name: LLAMA_CLBLAST
#      value: 1
              - name: GO_TAGS
                value: stablediffusion
              - name: DEBUG
                value: 'true'

            resources:
              requests:
                gpu.intel.com/i915: 1
                cpu: 200m
                memory: 2000Mi
              limits:
                gpu.intel.com/i915: 1
                memory: 40000Mi
            probes:
              liveness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /healthz
                    port: &port 8080

                  initialDelaySeconds: 300
                  periodSeconds: 30
                  timeoutSeconds: 1
                  failureThreshold: 6
              readiness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /readyz
                    port: *port
                  initialDelaySeconds: 300
                  periodSeconds: 30
                  timeoutSeconds: 1
                  failureThreshold: 6
              startup:
                enabled: false

    service:
      main:
        type: LoadBalancer
        ports:
          http:
            port: *port
    ingress:
      main:
        enabled: true
        annotations:
          hajimari.io/enable: 'true'
          hajimari.io/icon: eos-icons:ai
          hajimari.io/info: Local AI
          hajimari.io/group: Home
          cert-manager.io/cluster-issuer: letsencrypt-production
          traefik.ingress.kubernetes.io/router.entrypoints: websecure
          traefik.ingress.kubernetes.io/router.middlewares: networking-chain-authelia@kubernetescrd
        hosts:
          - host: &uri ai.${SECRET_DEV_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  name: main
                  port: http
        tls:
          - hosts:
              - *uri
            secretName: *uri
    persistence:
      models:
        enabled: true
        storageClass: longhorn
        size: 30Gi
        type: pvc
        accessMode: ReadWriteOnce

    lifecycle:
      postStart:
        exec:
          command:
            - /bin/bash
            - -c
            - >
              apt install libclblast-dev -y &&
              mkdir /tmp/neo &&
              cd /tmp/neo &&
              wget https://github.com/intel/intel-graphics-compiler/releases/download/igc-1.0.13700.14/intel-igc-core_1.0.13700.14_amd64.deb
              &&
              wget https://github.com/intel/intel-graphics-compiler/releases/download/igc-1.0.13700.14/intel-igc-opencl_1.0.13700.14_amd64.deb
              &&
              wget https://github.com/intel/compute-runtime/releases/download/23.13.26032.30/intel-level-zero-gpu-dbgsym_1.3.26032.30_amd64.ddeb
              &&
              wget https://github.com/intel/compute-runtime/releases/download/23.13.26032.30/intel-level-zero-gpu_1.3.26032.30_amd64.deb
              &&  wget https://github.com/intel/compute-runtime/releases/download/23.13.26032.30/intel-opencl-icd-dbgsym_23.13.26032.30_amd64.ddeb
              &&
              wget https://github.com/intel/compute-runtime/releases/download/23.13.26032.30/intel-opencl-icd_23.13.26032.30_amd64.deb
              &&
              wget https://github.com/intel/compute-runtime/releases/download/23.13.26032.30/libigdgmm12_22.3.0_amd64.deb
              &&
              dpkg -i *.deb 

